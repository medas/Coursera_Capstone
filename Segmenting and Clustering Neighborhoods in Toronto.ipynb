{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Segmenting and Clustering Neighborhoods in Toronto"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Table of Contents\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n\n<font size = 3>\n\n1. <a href=\"#item1\">Question 1</a>\n    \n1.1. <a href=\"#item1\">Conclusion</a>\n2. <a href=\"#item2\">Question 2</a>\n    \n2.1. <a href=\"#item1\">Conclusion</a>\n    \n3. <a href=\"#item3\">Question 3</a>\n    \n3.1. <a href=\"#item1\">Conclusion</a>\n</font>\n</div>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 1. Question 1"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "*Use the Notebook to build the code to scrape the following Wikipedia page, https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M, in order to obtain the data that is in the table of postal codes and to transform the data into a pandas dataframe like the one shown below:*\n\n<img src = \"https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/7JXaz3NNEeiMwApe4i-fLg_40e690ae0e927abda2d4bde7d94ed133_Screen-Shot-2018-06-18-at-7.17.57-PM.png?expiry=1588636800000&hmac=ssKIQrsG6VHIIby2_yiH4jQ1yUt124BPn_UWPv6ncGk\" width=\"500\" height=\"500\" />"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The code to scrape the following Wikipedia page, https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M, in order to obtain the data that is in the table of postal codes and to transform the data into a pandas dataframe like the one shown below:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "(optional) If needed, install the *pip* package in the current Jupyter kernel."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# import sys\n# !{sys.executable} -m pip install BeautifulSoup4"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Scrape the webpage from Wikipedia that contains the complete list of postal codes for the city of Toronto. We use the *request* library to scrape the page."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import requests\nwebsite_url = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We will use  the *BeautifulSoup* library to handle the content of the page. We will use the *lxml* parser since its the recommended one and also reportedly very fast."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from bs4 import BeautifulSoup\nsoup = BeautifulSoup(website_url,'lxml')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We will look for a table in the code. *BeautifulSoup* allows us to search for an HTML element by it's type. So lets look for a *table*."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "soup.table.name"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "There is one table element named 'table' in the text. We will get the first table row (the first *tr* element) to see if this has table headers."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#another way to get the same result: soup.table.tr.findAll()\nprint(soup.table.tr.text)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "So now lets scrape the postal codes to a Data Frame. We will iterate in the table and look for all the *tr* elements, the rows and scrape the data from it. Since the first row contains the row header we will need to remove it from the data frame after all the data is loaded."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import pandas as pd"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The list of headers for our data frame."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "headers=[\"Postalcode\",\"Borough\",\"Neighborhood\"]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The data frame is named *df_toronto*."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto = pd.DataFrame(columns= headers)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "for row in soup.table.find_all('tr'):\n    row_data=[]\n    for data in row.find_all('th'):\n        row_data.append(data.text.strip())\n    for data in row.find_all('td'):\n        row_data.append(data.text.strip())\n    df_toronto.loc[len(df_toronto)] = row_data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now we have our data frame, We should check it."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We need to remove the first row from the Dataset."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# delete the first row from the dataFrame\ndf_toronto.drop(0, inplace=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now we will remove the postal codes not assigned to a borough."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Get names of indexes for which the column Borough has a value \"Not assigned\"\nnot_assigned = df_toronto[df_toronto['Borough'] =='Not assigned'].index\n\n# Delete the row indexes from the data frame\ndf_toronto.drop(not_assigned, inplace=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can check how many rows the data frame contains now."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "How many distinct postal codes are in the data frame?"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto.nunique()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "So there is no need to merge different rows since this version of the page has no longer repeated postal codes. But the neighbourhood names are not separeted by commas but by slashes /. We can fix this."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto.Neighborhood = df_toronto.Neighborhood.replace(\" /\", ',', regex=True)\ndf_toronto.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 1.1. Conclusion\n\nWe can see the full data frame below."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2. Question 2\n\nNow that you have built a dataframe of the postal code of each neighborhood along with the borough name and neighborhood name, in order to utilize the Foursquare location data, we need to get the latitude and the longitude coordinates of each neighborhood.\n\nIn an older version of this course, we were leveraging the Google Maps Geocoding API to get the latitude and the longitude coordinates of each neighborhood. However, recently Google started charging for their API: http://geoawesomeness.com/developers-up-in-arms-over-google-maps-api-insane-price-hike/, so we will use the Geocoder Python package instead: https://geocoder.readthedocs.io/index.html.\n\nThe problem with this Package is you have to be persistent sometimes in order to get the geographical coordinates of a given postal code. So you can make a call to get the latitude and longitude coordinates of a given postal code and the result would be None, and then make the call again and you would get the coordinates. So, in order to make sure that you get the coordinates for all of our neighborhoods, you can run a while loop for each postal code. Taking postal code M5G as an example, your code would look something like this:\n\nGiven that this package can be very unreliable, in case you are not able to get the geographical coordinates of the neighborhoods using the Geocoder package, here is a link to a csv file that has the geographical coordinates of each postal code: http://cocl.us/Geospatial_data\n\nUse the Geocoder package or the csv file to create the following dataframe:\n<img src=\"https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/HZ3jNHNOEeiMwApe4i-fLg_f44f0f10ccfaf42fcbdba9813364e173_Screen-Shot-2018-06-18-at-7.18.16-PM.png?expiry=1588636800000&hmac=epN7y9Ean0VJJ-40CNmcZ9ztJhgYTUYI5v09sgxi9WY\" width=\"500\" height=\"500\" />"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "There was no data retrieved from Google using the *geocoder* library. *Geocoder* offers other geodata sources, for example *arcgis* for the same purpose.\n\nI will first retrieve the coordinates data from the csv file available for this question."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#add Geo-spatial data\ndf_coord= pd.read_csv(\"http://cocl.us/Geospatial_data\")\n#dfll.set_index(\"Postcode\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can check that the file was loaded in the data frame."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_coord.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We need to rename the first column to *Postalcode*  so we can merge this data frame with the *boroughs* dataframe we previously created, *df_toronto*."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_coord.rename(columns={'Postal Code':'Postalcode'},inplace=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This dataframe has the same number of rows."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_coord.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Lets merge the two datagrames, using the *Postalcode* column as the column name to join on."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_all_boroughs = pd.merge(df_toronto, df_coord, on = 'Postalcode')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The result of the merge is the dataframe *df_all_boroughs*."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_all_boroughs.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Retrieving the geo coordinates from the ArcGis database using the *geocoder* library"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Since using geocoder to retrieve geo coordinates from Google was not working, we used another well known geo data provider, *ArcGis*. \nWe don't need an API key to use it."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "First we need to install *geocoder* and import it."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import sys\n!{sys.executable} -m pip install geocoder"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import geocoder"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Using *geocoder* to retrieve geo data from Google is not working:"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import geocoder\ng = geocoder.google('Mountain View, CA')\ng.latlng\nprint(g.latlng)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "So we will create a function to retrieve geo data from ArcGis using *geocoder*."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def get_latlng(postal_code):\n    # initialize your variable to None\n    lat_lng_coords = None\n    # loop until you get the coordinates\n    while(lat_lng_coords is None):\n        g = geocoder.arcgis('{}, Toronto, Ontario'.format(postal_code))\n        lat_lng_coords = g.latlng\n    return lat_lng_coords[0],lat_lng_coords[1]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "If we feed the function with an address we will get the geo data for it."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "get_latlng('M3A')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We will create a new column on the data frame and fill it with the geo data for the postal code in each line."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto['coord'] = df_toronto.Postalcode.apply(lambda x: get_latlng(x))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The data frame now has all the geo data we need but now we need to split it in two columns, *Latitude* and *Longitude* and drop the *coord* column after it."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto['Latitude'] = df_toronto.coord.apply(lambda x: x[0])\ndf_toronto['Longitude'] = df_toronto.coord.apply(lambda x: x[1])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto.drop(\"coord\", axis=1, inplace=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Finally, we have the data frame with the desired data, labeled as we wanted."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can see that both data frames have the same data, with slight differences only on latitude and longitude values can be explained by the different option how to define the coordinates of a neighbourhood. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto.nunique()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_toronto[df_toronto.Neighborhood.duplicated()]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_all_boroughs.nunique()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_all_boroughs[df_all_boroughs.Neighborhood.duplicated()]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.1. Conclusion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We retrieved the geo data from two sources. The first source was the CSV file provided by IBM and the second source was the geo data from ArcGis retrieved using *geocoder*."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# from a CSV file\ndf_all_boroughs"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# from the ArcGis geo data using the geocoder library\ndf_toronto"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 3. Question 3"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Explore and cluster the neighborhoods in Toronto. You can decide to work with only boroughs that contain the word Toronto and then replicate the same analysis we did to the New York City data. It is up to you.\n\nJust make sure:\n\nto add enough Markdown cells to explain what you decided to do and to report any observations you make.\nto generate maps to visualize your neighborhoods and how they cluster together.\nOnce you are happy with your analysis, submit a link to the new Notebook on your Github repository."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 1. Explore Toronto and select the neighborhoods to cluster"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We first display a map of all Toronto neighborhoods."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "address = 'Toronto, CA'\n\ngeolocator = Nominatim(user_agent=\"toronto_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of the city of Toronto are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map of Toronto using latitude and longitude values\nmap_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(df_toronto['Latitude'], df_toronto['Longitude'], df_toronto['Borough'], df_toronto['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We will focus on the downton of Toronto. We will cluster only the neighbourhoods included in the Toronto Downtown borough."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "downtown_data = df_toronto[df_toronto['Borough'] == 'Downtown Toronto'].reset_index(drop=True)\ndowntown_data.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Display now the map zooming in Downtown Toronto."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "address = 'Downtown Toronto, Toronto, ON'\n\ngeolocator = Nominatim(user_agent=\"toronto_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Downtown Toronto are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "# create map of Downtown Toronto using latitude and longitude values\nmap_downtown = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# add markers to map\nfor lat, lng, label in zip(downtown_data['Latitude'], downtown_data['Longitude'], downtown_data['Neighborhood']):\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_downtown)  \n    \nmap_downtown"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Foursquare Api credentials"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "CLIENT_ID = 'XEJXIC4ABL0SSRAWKMYJ5UKIO2DRR0HIU14KOCR5YIHZR2MP' # your Foursquare ID\nCLIENT_SECRET = 'P0L3PE2EPASSSHZS513AFA15UNOARCAMHXVRS1ZOUYKOMG3R' # your Foursquare Secret\n\n# needed now\nACCESS_TOKEN = 'CIIQUWECMQFQIEDQW3IKZUNBIJTLCXFW4DFQAVX13CZBRQBD'\nVERSION = '20180605' # Foursquare API version"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Exploring the geo data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Get the first neighborhood in the dataset and explore the information we can get from Foursquare related to it."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "downtown_data.loc[0, 'Neighborhood']"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Get the neighborhood's latitude and longitude values."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "neighborhood_latitude = downtown_data.loc[0, 'Latitude'] # neighborhood latitude value\nneighborhood_longitude = downtown_data.loc[0, 'Longitude'] # neighborhood longitude value\n\nneighborhood_name = downtown_data.loc[0, 'Neighborhood'] # neighborhood name\n\nprint('Latitude and longitude values of {} are {}, {}.'.format(neighborhood_name, \n                                                               neighborhood_latitude, \n                                                               neighborhood_longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#### Exploring the venues around it. Lets use a 500 metres around the latitude and longitude we have."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "LIMIT = 100 # limit of number of venues returned by Foursquare API\nradius = 500 # define radius\n\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID, \n    CLIENT_SECRET, \n    VERSION, \n    neighborhood_latitude, \n    neighborhood_longitude, \n    radius, \n    LIMIT)\n\nresults = requests.get(url).json()\nresults"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "From the Foursquare lab in the previous module, we know that all the information is in the *items* key. Before we proceed, we will add a **get_category_type** function to get the category type, pretty obvious, right?"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now we are ready to clean the json and structure it into a *pandas* dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "venues = results['response']['groups'][0]['items']\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('We have a total of {} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 3.2. Explore Neighborhoods in Downtown Toronto"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "So now we will do the same data collection for all the neighborhoods in our selection."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "First we define a function to retrive the data for each neighborhood."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Using this fuction we create a new dataframe with all the venues in a 500 meters radius of each neighborhood. The dataframe is called *downtown_venues*."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "downtown_venues = getNearbyVenues(names=downtown_data['Neighborhood'],\n                                   latitudes=downtown_data['Latitude'],\n                                   longitudes=downtown_data['Longitude']\n                                  )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Lets check the size of the resulting dataframe"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(downtown_venues.shape)\ndowntown_venues.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Grouping the dataframe by neighborhood we can see how many venues are in each neighborhood."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "downtown_venues.groupby('Neighborhood').count()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### How many unique categories can be curated from all the returned venues"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('There are {} uniques categories.'.format(len(downtown_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 3. Analyze Each Neighborhood"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### We now create a dataframe will all the venues and the total of each venue by neighborhood."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##### After we create the new dataframe we need to rearrange it so the neighborhood name appears as the first column, for that we dropt the column and then we add it from the original data frame."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one hot encoding\ndowntown_onehot = pd.get_dummies(downtown_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# drop the Neighborhood column (that doesn't have the names at the moment)\ndowntown_onehot = downtown_onehot.drop(['Neighborhood'], axis = 1)\n\n# add neighborhood column back to dataframe\ndowntown_onehot['Neighborhood'] = downtown_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [downtown_onehot.columns[-1]]  + list(downtown_onehot.columns[:-1])\ndowntown_onehot = downtown_onehot[fixed_columns]\n\ndowntown_onehot.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##### This data frame is huge, we can see that there are now the same number of rows we fetched before but the number of colunmns are now the same of the total of distinct venues we retrieved."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "downtown_onehot.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#### Next, we will group rows by neighborhood and by taking the mean of the frequency of occurrence of each category"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "downtown_grouped = downtown_onehot.groupby('Neighborhood').mean().reset_index()\ndowntown_grouped"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Grouping by *Neighborhood* provied a new data frame with the 19 neighborhoods and the number of rows equal to the number of unique venues we found earlier. The data in the set is now showing us the relative size of each type of venue in each neighborhood. Check this in the table above and the dimension in the line below."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "downtown_grouped.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Print each neighborhood along with the top 5 most common venues"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 5\n\nfor hood in downtown_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = downtown_grouped[downtown_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Once again, we create *pandas* dataframe with this data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "First, we add a function to sort the venues in descending order."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now we create the new dataframe and display the top 10 venues for each neighborhood."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 15\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = downtown_grouped['Neighborhood']\n\nfor ind in np.arange(downtown_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(downtown_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 4. Cluster Neighborhoods"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Run *k*-means to cluster the neighborhood into 5 clusters."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# set number of clusters\nkclusters = 7\n\ndowntown_grouped_clustering = downtown_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(downtown_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Create a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\ndowntown_merged = downtown_data\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ndowntown_merged = downtown_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\ndowntown_merged.head() # check the last columns!"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Finally, we can visualize the resulting clusters."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=14)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(downtown_merged['Latitude'], downtown_merged['Longitude'], downtown_merged['Neighborhood'], downtown_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}